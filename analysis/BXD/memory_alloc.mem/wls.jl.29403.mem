        - 
        - ##################################################################
        - # wls: weighted least squares
        - ##################################################################
        - 
        - mutable struct LSEstimates
        0     b::Array{Float64, 2}
        -     sigma2::Float64
        -     ell::Float64
        - end
        - 
        - 
        - """
        - wls: Weighted least squares estimation
        - 
        - y = outcome, matrix
        - X = predictors, matrix
        - w = weights (positive, inversely proportional to variance), one-dim vector
        - 
        - """
        - function wls(y::Array{Float64, 2}, X::Array{Float64, 2}, w::Array{Float64, 1};
        -              reml::Bool = false, loglik::Bool = true, method = "qr")
        - 
        0     (n, p) = size(X); # get number of observations and the number of markers from geno dimensions      
        - 
        0     n = size(y, 1); # get number of observations       
        - 
        -     # check if weights are positive
     2048     if(any(w .<= .0))
        0         error("Some weights are not positive.")
        -     end
        - 
        -     # square root of the weights
    11776     sqrtw = sqrt.(w)
        - 
        -     # logdetXtX = logdet(X' * X); constant term that does not depend on the parameters (weights); is not needed
        - 
        -     # scale by weights
        0     yy = rowMultiply(y, sqrtw)
        0     XX = rowMultiply(X, sqrtw)
        - 
        -     # least squares solution
        -     # faster but numerically less stable
        0     if(method == "cholesky")
        0         fct = cholesky(XX'XX)
        0         b = fct\(XX'yy)
        0         logdetXXtXX = logdet(fct)
        -     end
        - 
        -     # slower but numerically more stable
        0     if(method == "qr")
        0         fct = qr(XX)
        0         b = fct\yy
        - 
        -         # logdetXXtXX = 2*logdet(fct.R) # need 2 for logdet(X'X)
        -         # logdetXXtXX = logdet(fct.R' * fct.R);
     1536         logdetXXtXX = 2*logabsdet(fct.R)[1];
        - 
        -     end
        - 
    11776     yyhat = XX*b
    11776     rss0 = sum((yy-yyhat).^2)
        - 
        0     if(reml)
        0         sigma2 = rss0/(n-p)
        -     else
        0         sigma2 = rss0/n
        -     end
        - 
        -     # see formulas (2) and (3) of Kang (2008)
        0     if(loglik)
        - 
        -         # ell = -0.5 * ( n*log(sigma2) + sum(log.(w)) + rss0/sigma2 )
    11776         ell = -0.5 * (n*log(sigma2) - sum(log.(w)) + rss0/sigma2)
        - 
        0         if(reml)
        -             # ell = ell + 0.5 * (p*log(2pi*sigma2) + logdetXtX - logdetXXtXX) # full log-likelihood including the constant terms;
        0             ell = ell + 0.5 * (p*log(sigma2) - logdetXXtXX)
        -         end
        -         
        -     else
        0         ell = missing;
        -     end
        - 
      512     return LSEstimates(b, sigma2, ell)
        - 
        - end
        - 
        - function ls(y::Array{Float64, 2}, X::Array{Float64, 2};
        -             reml::Bool = false, loglik = true)
        - 
        -     # number of individuals
        -     n = size(y,1)
        -     # number of covariates
        -     p = size(X,2)
        - 
        -     b = X\y # uses QR decomposition
        -     yhat = X*b
        -     rss0 = sum((y-yhat).^2)
        -     
        -     if( reml )
        -         sigma2 = rss0/(n-p)
        -     else
        -         sigma2 = rss0/n
        -     end
        - 
        -     if(loglik) 
        -         if ( reml )
        -             logdetSigma = (n-p)*log(sigma2)
        -         else
        -             logdetSigma = n*log(sigma2)
        -         end
        -         
        -         ell = -0.5 * ( logdetSigma + rss0/sigma2 )
        -     else
        -         ell = missing
        -     end
        - 
        -     return LSEstimates(b, sigma2, ell)
        - 
        - end
        - 
        - 
        - """
        - rss: residual sum of squares
        - 
        - y = outcome, matrix
        - X = predictors, matrix
        - 
        - Calculates the residual sum of squares using a Cholesky or
        - QRdecomposition.  The outcome matrix can be multivariate in which case
        - the function returns the residual sum of squares of each column. The
        - return values is a (row) vector of length equal to the number of columns of y.
        - 
        - """
        - function rss(y::Array{Float64, 2}, X::Array{Float64, 2}; method = "cholesky")
        - 
        0     r = resid(y, X; method)
4632143120     rss = reduce(+, r.^2, dims = 1)
        - 
        0     return rss
        - 
        - end
        - 
        - """
        - resid: calculate residuals
        - 
        - y = outcome, matrix
        - X = predictors, matrix
        - 
        - Calculates the residual sum of squares using a QR decomposition.  The
        - outcome matrix can be multivariate in which case the function returns
        - the residual matrix of the same size as the outcome matrix.
        - 
        - """
        - function resid(y::Array{Float64, 2}, X::Array{Float64, 2}; method = "cholesky")
        - 
        -     # least squares solution
        -     # faster but numerically less stable
        0     if(method=="cholesky")
 60735248         b = (X'X)\(X'y)
        -     end
        - 
        -     # slower but numerically more stable
        0     if(method=="qr")
        0     fct = qr(X)
        0     b = fct\y
        -     end
        - 
        -     # estimate yy and calculate rss
4636770080     yhat = X*b
        0     resid = y-yhat
        - 
        0     return resid
        - 
        - end
